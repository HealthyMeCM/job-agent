{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint A Test Notebook\n",
    "\n",
    "**Checkpoint A validates:**\n",
    "- Stage 0: Run + Config Snapshot (boot)\n",
    "- Stage 1: Source Planning (plan_sources)\n",
    "- Stage 2: Collection + Raw Snapshot Store (collect)\n",
    "\n",
    "This notebook tests each stage independently and then runs the full checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/cm/Desktop/PYTHON/repos/job_agent\n"
     ]
    }
   ],
   "source": [
    "# Setup path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0: Config & Boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 sources:\n",
      "  - anthropic_careers: careers_page [enabled]\n",
      "  - openai_careers: careers_page [enabled]\n"
     ]
    }
   ],
   "source": [
    "from core.config import Settings, load_config, SourceConfig, SourcesConfig\n",
    "\n",
    "# Load from YAML config\n",
    "sources_path = project_root / \"config\" / \"sources.yaml\"\n",
    "settings, sources = load_config(sources_path)\n",
    "\n",
    "print(f\"Loaded {len(sources.sources)} sources:\")\n",
    "for src in sources.sources:\n",
    "    status = \"enabled\" if src.enabled else \"disabled\"\n",
    "    print(f\"  - {src.source_id}: {src.source_type} [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings(database_url='sqlite:///./data/job_agent.db', snapshots_dir='./data/snapshots', config_snapshots_dir='./data/config_snapshots', dry_run=False, log_level='INFO', default_timeout=30, default_rate_limit=1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 20260205_202549_6c7b2e25\n",
      "Started: 2026-02-05 20:25:49.397058+00:00\n",
      "Status: RunStatus.RUNNING\n",
      "Config snapshot: data/config_snapshots/20260205_202549_6c7b2e25_config.json\n"
     ]
    }
   ],
   "source": [
    "from core.context import RunContext\n",
    "\n",
    "# Boot a run context\n",
    "ctx = RunContext.boot(settings=settings, sources=sources)\n",
    "\n",
    "print(f\"Run ID: {ctx.run_id}\")\n",
    "print(f\"Started: {ctx.started_at}\")\n",
    "print(f\"Status: {ctx.status}\")\n",
    "print(f\"Config snapshot: {ctx.config_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Source Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Planned 2 fetch tasks:\n",
      "  - anthropic_careers\n",
      "    URL: https://www.anthropic.com/careers\n",
      "    Type: careers_page\n",
      "    Rate limit: 0.5 rps\n",
      "\n",
      "  - openai_careers\n",
      "    URL: https://openai.com/careers\n",
      "    Type: careers_page\n",
      "    Rate limit: 0.5 rps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collectors.planner import plan_sources, FetchTask\n",
    "\n",
    "# Create fresh context for isolated test\n",
    "ctx = RunContext.boot(settings, sources)\n",
    "\n",
    "# Plan fetch tasks\n",
    "tasks = plan_sources(ctx)\n",
    "\n",
    "print(f\"\\nPlanned {len(tasks)} fetch tasks:\")\n",
    "for task in tasks:\n",
    "    print(f\"  - {task.source_id}\")\n",
    "    print(f\"    URL: {task.url}\")\n",
    "    print(f\"    Type: {task.source_type}\")\n",
    "    print(f\"    Rate limit: {task.fetch_policy.rate_limit_rps} rps\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage logs:\n",
      "  plan_sources: 2 -> 2 (completed)\n",
      "\n",
      "Metrics: 2 fetch tasks planned\n"
     ]
    }
   ],
   "source": [
    "# Check stage log\n",
    "print(\"Stage logs:\")\n",
    "for log in ctx.stage_logs:\n",
    "    print(f\"  {log.stage}: {log.items_in} -> {log.items_out} ({log.status})\")\n",
    "\n",
    "print(f\"\\nMetrics: {ctx.metrics.num_fetch_tasks} fetch tasks planned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FetchTask(url='https://www.anthropic.com/careers', source_id='anthropic_careers', source_type='careers_page', fetch_policy=FetchPolicy(rate_limit_rps=0.5, timeout_seconds=30, max_retries=3, follow_links=False), original_url='https://www.anthropic.com/careers', metadata={'company': 'Anthropic', 'priority': 'high', 'notes': 'AI safety company, key target'}),\n",
       " FetchTask(url='https://openai.com/careers', source_id='openai_careers', source_type='careers_page', fetch_policy=FetchPolicy(rate_limit_rps=0.5, timeout_seconds=30, max_retries=3, follow_links=False), original_url='https://openai.com/careers', metadata={'company': 'OpenAI', 'priority': 'high'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Collection\n",
    "\n",
    "This stage fetches URLs and stores raw snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 2 snapshots:\n",
      "  - anthropic_careers: OK\n",
      "    Content: 156637 bytes (text/html; charset=utf-8)\n",
      "    Hash: bd677a9799370c10\n",
      "  - openai_careers: FAIL: None\n"
     ]
    }
   ],
   "source": [
    "from evidence.snapshot import FileSnapshotStore\n",
    "from collectors.collector import collect\n",
    "import asyncio\n",
    "\n",
    "# Create snapshot store\n",
    "store = FileSnapshotStore(settings.snapshots_dir)\n",
    "\n",
    "# Run collection (async)\n",
    "snapshots = await collect(tasks, ctx, store)\n",
    "\n",
    "print(f\"\\nCollected {len(snapshots)} snapshots:\")\n",
    "for snap in snapshots:\n",
    "    status = \"OK\" if snap.success else f\"FAIL: {snap.error}\"\n",
    "    print(f\"  - {snap.source_id}: {status}\")\n",
    "    if snap.success:\n",
    "        print(f\"    Content: {snap.content_length} bytes ({snap.content_type})\")\n",
    "        print(f\"    Hash: {snap.content_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection metrics:\n",
      "  Successful: 1\n",
      "  Failed: 1\n",
      "\n",
      "Stage logs:\n",
      "  plan_sources: 2 -> 2 (completed)\n",
      "    Duration: 0.00s\n",
      "  collect: 2 -> 2 (completed)\n",
      "    Duration: 1.71s\n",
      "    Errors: ['openai_careers: HTTP 403']...\n"
     ]
    }
   ],
   "source": [
    "# Check metrics after collection\n",
    "print(\"Collection metrics:\")\n",
    "print(f\"  Successful: {ctx.metrics.num_snapshots_success}\")\n",
    "print(f\"  Failed: {ctx.metrics.num_snapshots_failed}\")\n",
    "\n",
    "print(\"\\nStage logs:\")\n",
    "for log in ctx.stage_logs:\n",
    "    print(f\"  {log.stage}: {log.items_in} -> {log.items_out} ({log.status})\")\n",
    "    if log.duration_seconds:\n",
    "        print(f\"    Duration: {log.duration_seconds:.2f}s\")\n",
    "    if log.errors:\n",
    "        print(f\"    Errors: {log.errors[:3]}...\")  # Show first 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Stored Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshots stored for run 20260205_203226_e30e9651:\n",
      "\n",
      "  ID: 1817939c6653\n",
      "  Source: anthropic_careers\n",
      "  URL: https://www.anthropic.com/careers\n",
      "  Status: 200\n",
      "  Content path: data/snapshots/20260205_203226_e30e9651/1817939c6653.content\n",
      "\n",
      "  ID: e0ec10090cd5\n",
      "  Source: openai_careers\n",
      "  URL: https://openai.com/careers\n",
      "  Status: 403\n",
      "  Content path: data/snapshots/20260205_203226_e30e9651/e0ec10090cd5.content\n"
     ]
    }
   ],
   "source": [
    "# List snapshots for this run\n",
    "stored_snapshots = store.list_by_run(ctx.run_id)\n",
    "\n",
    "print(f\"Snapshots stored for run {ctx.run_id}:\")\n",
    "for snap in stored_snapshots:\n",
    "    print(f\"\\n  ID: {snap.snapshot_id}\")\n",
    "    print(f\"  Source: {snap.source_id}\")\n",
    "    print(f\"  URL: {snap.canonical_url}\")\n",
    "    print(f\"  Status: {snap.status_code}\")\n",
    "    print(f\"  Content path: {snap.content_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of anthropic_careers:\n",
      "--------------------------------------------------\n",
      "<!DOCTYPE html><html lang=\"en\" class=\"anthropicsans_eac0b31f-module__tjnuGq__variable anthropicserif_87b6fa7d-module__quIBbW__variable anthropicmono_fae19af3-module__c5XAsG__variable copernicus_4da799c5-module__dijTSq__variable styrenea_f8492ab1-module__HimLXW__variable styreneb_278af5c6-module__wkOAdG__variable tiempostext_4eff4b4c-module__mpviCW__variable jetbrainsmono_7d7bdbc6-module__j_XgJq__variable\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width, initial-sca\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Preview content from first successful snapshot\n",
    "for snap in stored_snapshots:\n",
    "    if snap.success and snap.content_path:\n",
    "        content = store.get_content_by_path(snap.content_path)\n",
    "        if content:\n",
    "            preview = content[:500].decode('utf-8', errors='replace')\n",
    "            print(f\"Preview of {snap.source_id}:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(preview)\n",
    "            print(\"...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Checkpoint A Run\n",
    "\n",
    "Now run the complete checkpoint using the orchestration runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint A complete!\n",
      "Run ID: 20260205_204019_32a997a3\n",
      "Status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "from orchestration.runner import run_checkpoint_a_async, get_checkpoint_a_results\n",
    "\n",
    "# Run complete checkpoint A\n",
    "ctx = await run_checkpoint_a_async(sources_path=sources_path)\n",
    "\n",
    "print(f\"Checkpoint A complete!\")\n",
    "print(f\"Run ID: {ctx.run_id}\")\n",
    "print(f\"Status: {ctx.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run Summary ===\n",
      "Run ID: 20260205_204019_32a997a3\n",
      "Status: completed\n",
      "Started: 2026-02-05T20:40:19.220360+00:00\n",
      "Completed: 2026-02-05T20:40:21.309239+00:00\n",
      "\n",
      "=== Metrics ===\n",
      "  num_fetch_tasks: 2\n",
      "  num_snapshots_success: 1\n",
      "  num_snapshots_failed: 1\n",
      "  num_parse_success: 0\n",
      "  num_parse_failed: 0\n",
      "  num_role_leads_upserted: 0\n",
      "  num_candidates: 0\n",
      "\n",
      "=== Stages ===\n",
      "  plan_sources: 2 -> 2 (completed)\n",
      "  collect: 2 -> 2 (completed)\n"
     ]
    }
   ],
   "source": [
    "# Get detailed results\n",
    "results = get_checkpoint_a_results(ctx)\n",
    "\n",
    "print(\"\\n=== Run Summary ===\")\n",
    "summary = results['summary']\n",
    "print(f\"Run ID: {summary['run_id']}\")\n",
    "print(f\"Status: {summary['status']}\")\n",
    "print(f\"Started: {summary['started_at']}\")\n",
    "print(f\"Completed: {summary['completed_at']}\")\n",
    "\n",
    "print(\"\\n=== Metrics ===\")\n",
    "for key, val in summary['metrics'].items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(\"\\n=== Stages ===\")\n",
    "for stage in summary['stages']:\n",
    "    print(f\"  {stage['stage']}: {stage['items_in']} -> {stage['items_out']} ({stage['status']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Snapshots ===\n",
      "  anthropic_careers: OK\n",
      "    156637 bytes, text/html; charset=utf-8\n",
      "  openai_careers: FAIL: None\n"
     ]
    }
   ],
   "source": [
    "# Show snapshot details\n",
    "print(\"\\n=== Snapshots ===\")\n",
    "for snap in results['snapshots']:\n",
    "    status = \"OK\" if snap['success'] else f\"FAIL: {snap['error']}\"\n",
    "    print(f\"  {snap['source_id']}: {status}\")\n",
    "    if snap['success']:\n",
    "        print(f\"    {snap['content_length']} bytes, {snap['content_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Custom Sources\n",
    "\n",
    "Create sources programmatically for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test run: 20260205_204204_00a02f29\n",
      "Status: RunStatus.COMPLETED\n",
      "Snapshots: 1 success, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Create a minimal test source config\n",
    "test_sources = SourcesConfig(sources=[\n",
    "    SourceConfig(\n",
    "        source_id=\"test_httpbin\",\n",
    "        source_type=\"test\",\n",
    "        url=\"https://httpbin.org/html\",\n",
    "        enabled=True,\n",
    "        rate_limit_rps=1.0,\n",
    "        metadata={\"test\": True}\n",
    "    )\n",
    "])\n",
    "\n",
    "test_settings = Settings()\n",
    "\n",
    "# Run with test config\n",
    "test_ctx = await run_checkpoint_a_async(\n",
    "    settings=test_settings,\n",
    "    sources=test_sources\n",
    ")\n",
    "\n",
    "print(f\"Test run: {test_ctx.run_id}\")\n",
    "print(f\"Status: {test_ctx.status}\")\n",
    "print(f\"Snapshots: {test_ctx.metrics.num_snapshots_success} success, {test_ctx.metrics.num_snapshots_failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test run: 20260205_204326_f05a2cad\n",
      "Status: RunStatus.COMPLETED\n",
      "Snapshots: 1 success, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Create a minimal test source config\n",
    "test_sources = SourcesConfig(sources=[\n",
    "    SourceConfig(\n",
    "        source_id=\"norm_ai_careers\",\n",
    "        source_type=\"careers_page\",\n",
    "        url=\"https://www.norm.ai/careers/\",\n",
    "        enabled=True,\n",
    "        rate_limit_rps=1.0,\n",
    "        metadata={\"company\": \"Norm Ai\", \"priority\": \"high\", \"notes\": \"Legal AI company\"}\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "test_settings = Settings()\n",
    "\n",
    "# Run with test config\n",
    "test_ctx = await run_checkpoint_a_async(\n",
    "    settings=test_settings,\n",
    "    sources=test_sources\n",
    ")\n",
    "\n",
    "print(f\"Test run: {test_ctx.run_id}\")\n",
    "print(f\"Status: {test_ctx.status}\")\n",
    "print(f\"Snapshots: {test_ctx.metrics.num_snapshots_success} success, {test_ctx.metrics.num_snapshots_failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Normalization:\n",
      "  https://Example.com/Jobs/?utm_source=google&id=123\n",
      "  -> https://example.com/Jobs?id=123\n",
      "\n",
      "  https://example.com/jobs?id=123\n",
      "  -> https://example.com/jobs?id=123\n",
      "\n",
      "  HTTPS://EXAMPLE.COM/Jobs?id=123&utm_campaign=test\n",
      "  -> https://example.com/Jobs?id=123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from core.ids import normalize_url, content_hash, slugify\n",
    "\n",
    "# Test URL normalization\n",
    "test_urls = [\n",
    "    \"https://Example.com/Jobs/?utm_source=google&id=123\",\n",
    "    \"https://example.com/jobs?id=123\",\n",
    "    \"HTTPS://EXAMPLE.COM/Jobs?id=123&utm_campaign=test\",\n",
    "]\n",
    "\n",
    "print(\"URL Normalization:\")\n",
    "for url in test_urls:\n",
    "    normalized = normalize_url(url)\n",
    "    print(f\"  {url}\")\n",
    "    print(f\"  -> {normalized}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content hash: dffd6021bb2bd5b0\n",
      "\n",
      "Slugify:\n",
      "  Anthropic, Inc. -> anthropic-inc\n",
      "  OpenAI LP -> openai-lp\n",
      "  Google DeepMind -> google-deepmind\n"
     ]
    }
   ],
   "source": [
    "# Test content hashing\n",
    "test_content = b\"Hello, World!\"\n",
    "print(f\"Content hash: {content_hash(test_content)}\")\n",
    "\n",
    "# Test slugify\n",
    "test_names = [\"Anthropic, Inc.\", \"OpenAI LP\", \"Google DeepMind\"]\n",
    "print(\"\\nSlugify:\")\n",
    "for name in test_names:\n",
    "    print(f\"  {name} -> {slugify(name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint A Validation Checklist\n",
    "\n",
    "- [ ] Config loads from YAML\n",
    "- [ ] RunContext boots with unique run_id\n",
    "- [ ] Config snapshot is saved to disk\n",
    "- [ ] Sources are planned into FetchTasks\n",
    "- [ ] HTTP collection respects rate limits\n",
    "- [ ] Raw snapshots are stored with content\n",
    "- [ ] Snapshots can be retrieved by run_id\n",
    "- [ ] Stage logs capture metrics and timing\n",
    "- [ ] Errors are captured without crashing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
