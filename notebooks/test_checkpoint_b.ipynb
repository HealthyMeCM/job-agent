{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint B — Parse Stage Validation\n",
    "\n",
    "Validates Stage 3: raw HTML snapshots → structured CompanyProfiles via LLM extraction.\n",
    "\n",
    "**Prerequisites:**\n",
    "- `OPENAI_API_KEY` set in `.env`\n",
    "- Checkpoint A data exists (or will be collected fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup + imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from core.config import load_config\n",
    "\n",
    "sources_path = Path(\"../config/sources.yaml\")\n",
    "settings, sources = load_config(sources_path)\n",
    "\n",
    "print(f\"Settings loaded: verbose={settings.verbose}, llm_model={settings.llm_model}\")\n",
    "print(f\"Sources: {len(sources.sources)} configured\")\n",
    "print(f\"Parsed dir: {settings.parsed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Find existing snapshots\n",
    "from evidence.snapshot import FileSnapshotStore\n",
    "\n",
    "snapshot_store = FileSnapshotStore(settings.snapshots_dir)\n",
    "snapshots_dir = Path(settings.snapshots_dir)\n",
    "\n",
    "# Get the most recent run\n",
    "run_dirs = sorted(snapshots_dir.iterdir()) if snapshots_dir.exists() else []\n",
    "if run_dirs:\n",
    "    latest_run = run_dirs[-1].name\n",
    "    snapshots = snapshot_store.list_by_run(latest_run)\n",
    "    print(f\"Latest run: {latest_run}\")\n",
    "    print(f\"Snapshots: {len(snapshots)}\")\n",
    "    for s in snapshots:\n",
    "        print(\n",
    "            f\"  {s.source_id}: HTTP {s.status_code} | success={s.success} | {s.content_length} bytes\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No existing snapshots found — run Cell 5 first for a full pipeline run\")\n",
    "    snapshots = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Test adapter content extraction on a successful snapshot\n",
    "from parsing.adapters import get_adapter\n",
    "\n",
    "test_snapshot = next((s for s in snapshots if s.success), None)\n",
    "if test_snapshot:\n",
    "    html_bytes = snapshot_store.get_content(test_snapshot.snapshot_id)\n",
    "    assert html_bytes is not None, \"Content should exist\"\n",
    "\n",
    "    # Get adapter\n",
    "    adapter = get_adapter(test_snapshot.source_type)\n",
    "    print(f\"Adapter for '{test_snapshot.source_type}': {type(adapter).__name__}\")\n",
    "\n",
    "    # Find source metadata\n",
    "    source_meta = {}\n",
    "    for src in sources.sources:\n",
    "        if src.source_id == test_snapshot.source_id:\n",
    "            source_meta = {k: str(v) for k, v in src.metadata.items()}\n",
    "            break\n",
    "\n",
    "    if adapter:\n",
    "        content_block = adapter.extract_content(test_snapshot, html_bytes, source_meta)\n",
    "        print(f\"\\nMain text: {len(content_block.main_text)} chars\")\n",
    "        print(f\"Meta keys: {list(content_block.meta.keys())}\")\n",
    "        print(f\"Key links: {len(content_block.key_links)}\")\n",
    "        print(f\"Company hint: {content_block.company_hint}\")\n",
    "        print(\"\\n--- First 500 chars ---\")\n",
    "        print(content_block.main_text[:500])\n",
    "else:\n",
    "    print(\"No successful snapshot to test — run Cell 5 first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test LLM extraction on a single snapshot\n",
    "from core import verbose\n",
    "from parsing.llm import extract_company_profile\n",
    "\n",
    "verbose.configure(2)  # DEBUG level\n",
    "\n",
    "if test_snapshot and adapter:\n",
    "    profile, log = extract_company_profile(\n",
    "        content_block=content_block,\n",
    "        model=settings.llm_model,\n",
    "        snapshot_id=test_snapshot.snapshot_id,\n",
    "        source_id=test_snapshot.source_id,\n",
    "        url=test_snapshot.canonical_url,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nStatus: {log.status}\")\n",
    "    print(f\"Tokens: {log.llm_tokens_used}\")\n",
    "    print(f\"Duration: {log.duration_ms:.0f}ms\")\n",
    "\n",
    "    if profile:\n",
    "        print(\"\\n--- CompanyProfile ---\")\n",
    "        print(f\"Name: {profile.name}\")\n",
    "        print(f\"Domain: {profile.domain}\")\n",
    "        print(f\"Summary: {profile.summary}\")\n",
    "        print(f\"Tags ({len(profile.tags)}): {profile.tags}\")\n",
    "        print(f\"Confidence: {profile.confidence}\")\n",
    "        print(f\"Unknowns: {profile.unknowns}\")\n",
    "        print(\"\\n--- Signals ---\")\n",
    "        for sig in profile.signals:\n",
    "            print(f\"  {sig.name} = {sig.value}\")\n",
    "            print(f'    Evidence: \"{sig.evidence.text[:80]}...\"')\n",
    "            print(f\"    Context: {sig.evidence.context}\")\n",
    "    else:\n",
    "        print(f\"\\nErrors: {log.errors}\")\n",
    "else:\n",
    "    print(\"Skipped — no snapshot available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run full Checkpoint B pipeline\n",
    "from orchestration.runner import get_checkpoint_b_results, run_checkpoint_b_async\n",
    "\n",
    "verbose.configure(2)  # DEBUG level\n",
    "\n",
    "ctx = await run_checkpoint_b_async(sources_path=sources_path)\n",
    "\n",
    "print(\"\\nCheckpoint B complete!\")\n",
    "print(f\"Run ID: {ctx.run_id}\")\n",
    "print(f\"Status: {ctx.status}\")\n",
    "print(\n",
    "    f\"Snapshots: {ctx.metrics.num_snapshots_success} success, {ctx.metrics.num_snapshots_failed} failed\"\n",
    ")\n",
    "print(\n",
    "    f\"Parse: {ctx.metrics.num_parse_success} success, {ctx.metrics.num_parse_failed} failed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inspect persisted files\n",
    "parsed_dir = Path(settings.parsed_dir) / ctx.run_id\n",
    "\n",
    "profiles_path = parsed_dir / \"profiles.json\"\n",
    "parse_log_path = parsed_dir / \"parse_log.json\"\n",
    "\n",
    "print(f\"Parsed dir: {parsed_dir}\")\n",
    "print(f\"profiles.json exists: {profiles_path.exists()}\")\n",
    "print(f\"parse_log.json exists: {parse_log_path.exists()}\")\n",
    "\n",
    "if profiles_path.exists():\n",
    "    with open(profiles_path) as f:\n",
    "        profiles_data = json.load(f)\n",
    "    print(f\"\\nProfiles: {len(profiles_data)}\")\n",
    "    for p in profiles_data:\n",
    "        print(f\"  {p['name']} ({p['domain']}) — confidence={p['confidence']}\")\n",
    "        print(f\"    Tags: {p['tags'][:5]}...\")\n",
    "        print(f\"    Signals: {len(p['signals'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Inspect parse logs\n",
    "if parse_log_path.exists():\n",
    "    with open(parse_log_path) as f:\n",
    "        logs_data = json.load(f)\n",
    "    print(f\"Parse logs: {len(logs_data)}\")\n",
    "    for log_entry in logs_data:\n",
    "        print(f\"  {log_entry['source_id']}: {log_entry['status']}\")\n",
    "        print(f\"    Model: {log_entry.get('llm_model', 'N/A')}\")\n",
    "        print(f\"    Tokens: {log_entry.get('llm_tokens_used', 0)}\")\n",
    "        print(f\"    Duration: {log_entry.get('duration_ms', 0):.0f}ms\")\n",
    "        if log_entry.get(\"errors\"):\n",
    "            print(f\"    Errors: {log_entry['errors']}\")\n",
    "        if log_entry.get(\"warnings\"):\n",
    "            print(f\"    Warnings: {log_entry['warnings']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Validation checklist\n",
    "results = get_checkpoint_b_results(ctx)\n",
    "\n",
    "checks = {\n",
    "    \"Pipeline completed\": ctx.status.value == \"completed\",\n",
    "    \"At least 1 snapshot collected\": ctx.metrics.num_snapshots_success >= 1,\n",
    "    \"At least 1 profile extracted\": len(results[\"profiles\"]) >= 1,\n",
    "    \"Profiles persisted to disk\": profiles_path.exists(),\n",
    "    \"Parse logs persisted to disk\": parse_log_path.exists(),\n",
    "    \"Profile has name\": bool(results[\"profiles\"])\n",
    "    and bool(results[\"profiles\"][0].get(\"name\")),\n",
    "    \"Profile has tags\": bool(results[\"profiles\"])\n",
    "    and len(results[\"profiles\"][0].get(\"tags\", [])) >= 5,\n",
    "    \"Profile has signals with evidence\": bool(results[\"profiles\"])\n",
    "    and len(results[\"profiles\"][0].get(\"signals\", [])) >= 1,\n",
    "    \"Profile has confidence score\": bool(results[\"profiles\"])\n",
    "    and results[\"profiles\"][0].get(\"confidence\", 0) > 0,\n",
    "}\n",
    "\n",
    "print(\"=== Checkpoint B Validation ===\")\n",
    "all_pass = True\n",
    "for check, passed in checks.items():\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    if not passed:\n",
    "        all_pass = False\n",
    "    print(f\"  [{status}] {check}\")\n",
    "\n",
    "print(f\"\\n{'All checks passed!' if all_pass else 'Some checks FAILED'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}